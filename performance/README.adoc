= Performance Benchmark

This module contains a performance benchmark, which measures the time spent by TRIO while computing
robustness metrics. 

This benchmark proceeds in three steps:

. Generate graphs randomly, whose number of vertices may be varied as needed. These 
graphs are generated by the given R script and serialized on disk in separate CSV files.

. The TRIO benchmark transforms these random graphs into TRIO topologies and computes
all robustness metrics, while measuring the time spent for each graph.

. Data can be quickly visualized and analysed using the given R script, if need be.

CAUTION: Running this benchmark will consume time and disk space. The generation and analysis of 
graphs will *takes around two hours*, depending on the underlying power, and the graphs serialized on 
disk will *need around 2 GB of memory*.

== Generating Random Graphs

The generation of random graphs is done by a separate R script, built upon the 
link:http://igraph.org/r/[iGraph library]. It covers the generation of three main families of 
graphs, namely:

* link:http://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model[Erdos-Renyi graphs], 
which are graphs whose edges are created with a fixed probability. 

* link:http://en.wikipedia.org/wiki/Small-world_network[Small-world graphs], which are graphs where 
the distance between all pair of nodes remains below a given threshold. These are generated using 
the Watts & Strogatz model.

* link:http://en.wikipedia.org/wiki/Scale-free_network[Scale-free graphs], where a few nodes have 
significantly more connexions than the others. They are generated by using the Barabasi & Albert model. 

The generation of random graphs encompasses the computation of several topological
metrics, including density, diameter, average node degree, and several measures of centrality. When 
the generation completes, these metrics are available in the file `graphs.csv`. The generation is 
started by the following command:

----
$> R CMD BATCH "--args generate" benchmark.R
----

The graphs are identified by a single natural number and saved as edge lists in separate CSV files.

NOTE: The R script requires the *igraph* package to be available. To do so, open an R console, 
input `install.package("igraph");`, and follows the given instructions.

== Running the Performance Benchmark

The benchmark in itself is a regular Java application that can be run from the command line, as shown 
below:

.Sample output of the performance benchmark, run from the command line
----
$> java -cp "bin/*" eu.diversify.trio.performance.Runner
TRIO - Topology Robustness Indicator
Copyright (C) 2015 - SINTEF ICT

Reading configuration in 'setup.properties'
 - 50 topologies(s) ;
 - from files 'graph_%d.csv' in './graphs' ;
 - 15 % as warmup.


Warming-up ...
Progress: 100 % [avg. duration =  322.55 ms]

Evaluating performance ...
Progress: 100 % [avg. duration =  360.45 ms]

That's all folks!
----

== Data Visualization & Regression

The given R script can also be used to view the data generated by the performance analysis, as a 
PDF file named `benchmark.pdf`. It can be obtained by running the R script with the 'plot' argument.

----
$> R CMD BATCH "--args plot" benchmark.R
----

In addition, the R script can a run a statistical regression analysis to measure the influence that 
different factors may have on the duration, such as the type of graphs (i.e., random, small-world, or
scale-free), their density, etc. The regression analysis is triggered by running the benchmark R 
script with the 'regression' parameter, as shown below:

----
$> R CMD BATCH "--args regression" benchmark.R
----
The summary of the regression analysis is automatically written in `regression.txt`.

== Tuning the Benchmark

Some parameters which govern the generation of graphs (e.g, graphs size) can be setup in the 
`setup.properties` file. The list of properties is given below:

.Configuration properties which can influence the benchmark
[options="header"]
|=======================
| Key | Type | Description | Examples
| `first.graph.id` | positive integer  | The id of the first graph generated by the R script | 2, 3, 100
| `last.graph.id` | positive integer  | The id of the last graph generated by the R script. Must be greater than `first.graph.id`. | 2, 3, 101
| `min.assembly.size` | positive integer  | The minimum number of vertices to generate in a graph | 2, 3, 100
| `max.assembly.size` | positive integer  | The maximum number of vertices to generate in a graph. Must be greater than `min.assembly.size` | 2, 3, 101
| `graph.directory` | text  | The path to the directory where graph CSV files must be written | "./graphs"
| `graph.file.pattern`| text | The C-like pattern to be used to build the name of graph files | "graph_%d.csv"
| `warmup.ratio`| positive real within [0, 1] | The ratio of graphs to be processed to warmup the JIT compiler of the JVM | 0.20 
|=======================

Note that the performance benchmark includes a warmup phase, which ensures that the underlying JIT compiler of 
the JVM has enough time to compile the code, and stabilize the performance measures. The number of 
graphs used in the warmup phase is controlled by the `warmup.ratio` property.
